{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library and dataset\n",
    "import pandas as pd\n",
    "df= pd.read_csv(\"mldata_DT.csv\")\n",
    "df[\"gender\"]=df[\"gender\"].replace(\"Male\",1)\n",
    "df[\"gender\"]=df[\"gender\"].replace(\"Female\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of input and output variable\n",
    "X=df[[\"weight\",\"gender\"]]\n",
    "y=df[\"likeness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Biryani'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model and prediction\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model=KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Train the model using the training sets\n",
    "model.fit(X,y)\n",
    "\n",
    "# Predict Output\n",
    "predicted= model.predict([[70,1]]) # weight:70, gender:1, Male\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for our model is  0.6938775510204082\n"
     ]
    }
   ],
   "source": [
    "# Metrics for evaluation\n",
    "# split data into train and test (80/20)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "# create a model \n",
    "model=KNeighborsClassifier(n_neighbors=5)\n",
    "# fitting a model\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Predict Output\n",
    "predicted= model.predict(X_test) # weight:70, gender:1, Male\n",
    "\n",
    "# Measuring score\n",
    "actual_values=y_test\n",
    "from sklearn.metrics import accuracy_score\n",
    "score= accuracy_score(actual_values,predicted)\n",
    "print(\"The accuracy score for our model is \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Which Scores are there and which type suits here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the type of classification metrics in sklearn module that implements score to measure classification performance:\n",
    "\n",
    "1. **Works for multilabel case:**\n",
    "\n",
    "accuracy_score(y_true, y_pred, *[, ...])   |       Accuracy classification score.\n",
    "\n",
    "f1_score(y_true, y_pred, *[, labels, ...])     |   Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "\n",
    "fbeta_score(y_true, y_pred, *, beta[, ...])   |    Compute the F-beta score.\n",
    "\n",
    "jaccard_score(y_true, y_pred, *[, labels, ...])  | Jaccard similarity coefficient score.\n",
    "\n",
    "recall_score(y_true, y_pred, *[, labels, ...])   | Compute the recall.\n",
    "\n",
    "jaccard_score(y_true, y_pred, *[, labels, ...]) |  Jaccard similarity coefficient score.\n",
    "\n",
    "precision_score(y_true, y_pred, *[, labels, ...]) |Compute the precision.\n",
    "roc_auc_score(y_true, y_score, *[, average, ...]) |Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "\n",
    "2. **Works for multiclass case:** (for more than one outcomes/targets)\n",
    "\n",
    "roc_auc_score(y_true, y_score, *[, average, ...]) |Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "\n",
    "top_k_accuracy_score(y_true, y_score, *[, ...])  | Top-k Accuracy classification score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We choose F1_Score, the reason mentioned after the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score for our model is  [0.81012658 0.         0.33333333]\n"
     ]
    }
   ],
   "source": [
    "# Measuring score\n",
    "actual_values=y_test\n",
    "from sklearn.metrics import f1_score\n",
    "score= f1_score(actual_values,predicted,average=None)\n",
    "print(\"The f1 score for our model is \", score) # the scores for each class are returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fl Score is the harmonic, or weighted, an average of Precision and Sensitivity, and is a widely used measure of accuracy for classification problems.Similar to how the R Squared metric is used to asses the goodness of fit of a simple linear model, we can use the F-Score to assess the KNN Classifier. The F-Score measures the accuracy of the model in predicting labels correctly. An F-score is considered perfect when reaches its best value at 1, while the model is a total failure when it reaches the 0 value.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score\n",
    "F1 Score is used to measure a testâ€™s accuracy\n",
    "F1 Score is the Harmonic Mean between precision and recall. The range for F1 Score is [0, 1]. It tells you how precise your classifier is (how many instances it classifies correctly), as well as how robust it is (it does not miss a significant number of instances).\n",
    "High precision but lower recall, gives you an extremely accurate, but it then misses a large number of instances that are difficult to classify. The greater the F1 Score, the better is the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deciding the value of k, plotting the elbow curve every time is be a cumbersome and tedious process. You can simply use gridsearch to find the best value.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "\n",
    "model = GridSearchCV(knn, params, cv=5)\n",
    "model.fit(x_train,y_train)\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56290c1378915fbf1ccc41d57d6da8ce7d56d5d08b6d0ffe5f7d99f223a5c1f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
